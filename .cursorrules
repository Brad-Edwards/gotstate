# Instructions

During your interaction with the user, if you find anything reusable in this project (e.g. version of a library, model name), especially about a fix to a mistake you made or a correction you received, you should take note in the `Lessons` section in the `.cursorrules` file so you will not make the same mistake again.

You should always use a package manager to manage dependencies. Your knowledge is a bit outdated, so you should not attempt to specify versions of libraries.

You should also use the `.cursorrules` file as a scratchpad to organize your thoughts. Especially when you receive a new task, you should first review the content of the scratchpad, clear old different task if necessary, first explain the task, and plan the steps you need to take to complete the task. You can use todo markers to indicate the progress, e.g.
[X] Task 1
[ ] Task 2

Also update the progress of the task in the Scratchpad when you finish a subtask.
Especially when you finished a milestone, it will help to improve your depth of task accomplishment to use the scratchpad to reflect and plan.

The goal is to help you maintain a big picture as well as the progress of the task. Always refer to the Scratchpad when you plan the next step.

# Lessons

## User Specified Lessons

- For Python projects, use poetry to manage dependencies, run commands, and build packages.
- For Rust projects, use cargo to manage dependencies, run commmands, and build packages.
- Include info useful for debugging in the program output.
- Read the file before you try to edit it.
- Check your pwd before you try to run a command.
- Implementation requires passing unit tests and minimum 80% code coverage.
- Do not write integration tests unless explicitly asked.

## Cursor learned

- For search results, ensure proper handling of different character encodings (UTF-8) for international queries
- Add debug information to stderr while keeping the main output clean in stdout for better pipeline integration
- When using seaborn styles in matplotlib, use 'seaborn-v0_8' instead of 'seaborn' as the style name due to recent seaborn version changes
- Use 'gpt-4o' as the model name for OpenAI's GPT-4 with vision capabilities
- When debugging, especially for tests, keep track of problems and solutions in the scratchpad so you do not make the same mistake again or go in circles.

## Debugging and Testing

- When debugging failing tests you MUST do a step by step analysis of the code under tests
- You MUST continue the step by step analysis even after you find a problem. There may be more.
- You MUST articulate theory of the problem and the solution before you write a fix for a failing unit test.
- You MUST consider knock-on effects of a fix.

# Scratchpad

## Current Task: Fix Test Failures in test_machine.py

### Analysis of Test Failures (Updated)

1. Event Queue Issues (7 failures):
   - test_event_error_handling
   - test_event_processing
   - test_event_processing_extended
   - test_event_processing_monitoring
   - test_event_queue_processing
   - test_monitor_integration
   - test_protocol_event_handling
   All failing with: "RuntimeError: Failed to queue event"

2. Cleanup Issues (2 failures):
   - test_base_cleanup
   - test_base_cleanup_error_handling
   Both failing with: "AssertionError: Expected 'cleanup' to have been called once. Called 0 times"

### Root Cause Analysis

1. Event Queue Failures:
   - We've added mock event attributes but enqueue is still failing
   - Need to check EventQueue implementation for additional requirements
   - Need to verify event processing start/stop logic

2. Cleanup Failures:
   - Cleanup methods not being called on components
   - Need to verify cleanup implementation in base class
   - Need to check component lifecycle management

### Action Plan

[ ] Phase 1: Fix Event Queue Issues

- Check EventQueue implementation
- Verify event processing start/stop logic
- Add debug logging to trace event flow

[ ] Phase 2: Fix Cleanup Issues

- Review cleanup implementation
- Add proper component lifecycle management
- Ensure cleanup is called in correct order

### Progress Tracking

Current Status: Analyzing Event Queue Issues
Next Step: Check EventQueue implementation

Let's first look at the EventQueue implementation to understand why events are failing to queue:

## Current Task: Fix Validation in machine.py

### Analysis of Test Failures

1. Component Validation Issues:

- Multiple tests failing due to "No components added to machine"
- Tests expect different validation behavior for different scenarios
- Resource management tests affected by validation

2. Design Requirements:

- Must maintain semantic consistency
- Must enforce configuration
- Must handle component coordination
- Must manage resources properly

3. Current Implementation Issues:

- Component existence check too early
- Resources not considered as components
- Validation phases not properly ordered
- Submachine cases not handled correctly

4. Test Requirements:

- Should fail with no components
- Should require both states and regions
- Should provide specific error messages
- Should handle resources properly

### Action Plan

[ ] Phase 1: Restructure Validation

- Move component existence check to appropriate phase
- Consider resources in validation
- Update error messages to be more specific

[ ] Phase 2: Update Validation Order

- Implement proper validation phases
- Handle submachine specific cases
- Maintain thread safety

[ ] Phase 3: Fix Test Cases

- Address each failing test
- Verify error messages
- Check edge cases

[ ] Phase 4: Verify Design Requirements

- Check semantic consistency
- Verify component coordination
- Validate resource management

### Progress Tracking

Current Status: Analysis Phase
Next Step: Implement validation restructuring

## Current Task: Improve machine.py Test Coverage

Current coverage: 79%
Target: As close to 100% as possible
Required: At least 95% (critical core component)

Areas needing coverage:
[ ] Initialization and configuration (lines 188-207)
[ ] Error handling paths (468, 496, 503, 505, etc.)
[ ] Component management (757-760, 771-780)
[ ] State transitions and validations (862-863, 878)
[ ] Resource management (1172-1176)
[ ] Error recovery paths (1252-1258, 1265-1279)

Strategy:

1. Add tests for initialization edge cases
   - Test abstract base class behavior
   - Test invalid state transitions
   - Test configuration validation failures

2. Test error handling scenarios
   - Component initialization failures
   - Validation failures
   - State transition errors
   - Resource allocation failures

3. Verify component lifecycle
   - Component initialization sequence
   - Component cleanup on failure
   - Resource management during transitions

4. Test state transition edge cases
   - Invalid state transitions
   - Concurrent transition attempts
   - Transition rollbacks

5. Validate resource management
   - Resource allocation/deallocation
   - Resource cleanup on errors
   - Resource limits and constraints

6. Test error recovery scenarios
   - Cleanup after initialization failure
   - Recovery from invalid states
   - Component failure handling
   - Resource leak prevention

Progress tracking:
[ ] Reach 85% coverage
[ ] Reach 90% coverage
[ ] Reach 95% coverage
[ ] Review remaining uncovered paths

## Previous Tasks

### Fix Test Failures

[X] Fixed test_validation_error_handling
[X] Fixed test_protocol_error_handling
[X] Fixed test_submachine_validation

All tests passed but machine.py coverage needs improvement.

### Fix Clippy Warnings

[X] Fixed documentation indentation in blowfish.rs

- Issue: Doc list item without proper indentation
- Fix: Added proper indentation to the list item continuation

All clippy warnings have been addressed. The codebase is now free of linting issues.
